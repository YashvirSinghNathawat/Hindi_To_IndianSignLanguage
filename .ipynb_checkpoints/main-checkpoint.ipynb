{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682564fe-38e4-4f61-9222-6e2eb8e9122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS TAGS : (PSP)Postposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838562f8-d416-4c8d-9988-0da61144732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a79957-b38b-4b7a-af8d-b84adeca1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df11114d-3534-44d1-9ec8-e2288639e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_dataset.txt\", 'r',encoding='utf8') as file:\n",
    "            contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f765ee-ef87-4adc-afe0-859fe9133bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'only subject and verb': ['राम को स्कूल जाना है', 'मैं खुश हूं।', 'वह गाना गाता है।', 'तुम समय पर आओ।', 'वह चाय पीता है।', 'मेरा दोस्त बच्चों के साथ खेलता है।', 'आपका बेटा पढ़ाई कर रहा है।', 'सोनिया बहुत अच्छी है।', 'मेरे पास एक कुत्ता है।', 'तुम्हारा भाई टेनिस खेलता है।', 'राधा बाजार जाती है।', 'बच्चे पार्क में खेलते हैं।', 'उसका दोस्त उसकी मदद करता है।', 'वह खिड़की साफ़ करता है।', 'सोनल कुछ पढ़ती है।', 'तुम्हारी बहन संगीत सुनती है।', 'मेरी बेटी खाना बनाती है।', 'वह फ़िल्म देखता है।', 'आपका दादा स्कूल जाते हैं।', 'रोहन बहुत खुश है।', 'मेरे दोस्त रेस में भाग लेते हैं।']}\n"
     ]
    }
   ],
   "source": [
    "def create_sentence_dict(text):\n",
    "    \"\"\"Convert text content into a dictionary with categories as keys and sentences as values.\"\"\"\n",
    "    sentence_dict = {}\n",
    "    categories = text.split(\"\\n\\n\")\n",
    "    i = 0\n",
    "    length = len(categories)\n",
    "    \n",
    "    while i < length:\n",
    "        #print(categories[i],categories[i+1].splitlines())\n",
    "        sentences_list = []\n",
    "        for sentence in categories[i+1].splitlines():\n",
    "            if len(sentence)==0:\n",
    "                pass\n",
    "            else:\n",
    "                sentences_list.append(sentence)\n",
    "        sentence_dict[categories[i]] = sentences_list\n",
    "        i+=2\n",
    "        break\n",
    "    # for category in categories:\n",
    "    #     lines = category.split(\"\\n\")\n",
    "    #     key = lines[0].strip()\n",
    "    #     sentences = [line.strip() for line in lines[1:]]\n",
    "    #     sentence_dict[key] = sentences\n",
    "        \n",
    "    return sentence_dict\n",
    "# Create the dictionary\n",
    "sentence_dict = create_sentence_dict(contents)\n",
    "print(sentence_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aea6b3b4-3730-4745-9f15-a0d62dca1655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 00:50:06 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "2024-04-18:00:50:06,178 INFO     [core.py:214] Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb9ab79184e47f0a332e6b685b33e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 00:50:06 INFO: Downloaded file to C:\\Users\\Lenovo\\stanza_resources\\resources.json\n",
      "2024-04-18:00:50:06,298 INFO     [common.py:156] Downloaded file to C:\\Users\\Lenovo\\stanza_resources\\resources.json\n",
      "2024-04-18 00:50:07 INFO: Loading these models for language: hi (Hindi):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | hdtb          |\n",
      "| pos       | hdtb_charlm   |\n",
      "| lemma     | hdtb_nocharlm |\n",
      "| depparse  | hdtb_charlm   |\n",
      "=============================\n",
      "\n",
      "2024-04-18:00:50:07,51 INFO     [core.py:268] Loading these models for language: hi (Hindi):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | hdtb          |\n",
      "| pos       | hdtb_charlm   |\n",
      "| lemma     | hdtb_nocharlm |\n",
      "| depparse  | hdtb_charlm   |\n",
      "=============================\n",
      "\n",
      "2024-04-18 00:50:07 INFO: Using device: cpu\n",
      "2024-04-18:00:50:07,52 INFO     [core.py:287] Using device: cpu\n",
      "2024-04-18 00:50:07 INFO: Loading: tokenize\n",
      "2024-04-18:00:50:07,53 INFO     [core.py:293] Loading: tokenize\n",
      "2024-04-18 00:50:07 INFO: Loading: pos\n",
      "2024-04-18:00:50:07,59 INFO     [core.py:293] Loading: pos\n",
      "2024-04-18 00:50:07 INFO: Loading: lemma\n",
      "2024-04-18:00:50:07,331 INFO     [core.py:293] Loading: lemma\n",
      "2024-04-18 00:50:07 INFO: Loading: depparse\n",
      "2024-04-18:00:50:07,362 INFO     [core.py:293] Loading: depparse\n",
      "2024-04-18 00:50:07 INFO: Done loading processors!\n",
      "2024-04-18:00:50:07,627 INFO     [core.py:345] Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('hi', processors='tokenize,lemma,pos,depparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b1c9a602-d4ad-4cb3-81fc-60ed874caba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PSP', 'NN', 'VM', 'NNP', 'VAUX', 'SYM', 'JJ', 'NNPC', 'PRP', 'CC', 'NNC', 'QC', 'NST', 'DEM', 'RP', 'QF', 'NEG', 'RB', 'QCC', 'QO', 'INTF', 'JJC', 'WQ', 'RDP', 'UNK', 'PRPC', 'NSTC', 'RBC', 'QFC', 'CCC', 'INJ']\n"
     ]
    }
   ],
   "source": [
    "# Known POS Tags\n",
    "print(nlp.processors['pos'].get_known_xpos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "33f6665f-0f38-41bf-9027-df63b3347731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = sentence_dict['only subject and verb'][20]\n",
    "sentence = 'उसने धीरे चलकर स्टेशन पहुँचा।'\n",
    "sentence_list = sentence.split()\n",
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b1320a9b-4648-4618-ba99-8be972a419d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"उसने\",\n",
      "      \"lemma\": \"वह\",\n",
      "      \"upos\": \"PRON\",\n",
      "      \"xpos\": \"PRP\",\n",
      "      \"feats\": \"Case=Acc,Erg|Number=Sing|Person=3|PronType=Prs\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"nsubj\",\n",
      "      \"start_char\": 0,\n",
      "      \"end_char\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"धीरे\",\n",
      "      \"lemma\": \"धीरे\",\n",
      "      \"upos\": \"ADV\",\n",
      "      \"xpos\": \"RB\",\n",
      "      \"head\": 3,\n",
      "      \"deprel\": \"advmod\",\n",
      "      \"start_char\": 5,\n",
      "      \"end_char\": 9\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"चलकर\",\n",
      "      \"lemma\": \"चल\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VM\",\n",
      "      \"feats\": \"VerbForm=Conv\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"advcl\",\n",
      "      \"start_char\": 10,\n",
      "      \"end_char\": 14\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"स्टेशन\",\n",
      "      \"lemma\": \"स्टेशन\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Case=Nom|Gender=Masc|Number=Sing|Person=3\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"obl\",\n",
      "      \"start_char\": 15,\n",
      "      \"end_char\": 21\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"पहुँचा\",\n",
      "      \"lemma\": \"पहुँच\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VM\",\n",
      "      \"feats\": \"Aspect=Perf|Gender=Masc|Number=Sing|VerbForm=Part|Voice=Act\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"start_char\": 22,\n",
      "      \"end_char\": 28,\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"।\",\n",
      "      \"lemma\": \"।\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \"SYM\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 28,\n",
      "      \"end_char\": 29,\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5687e-97ff-4577-9fd8-fbc625a069ce",
   "metadata": {},
   "source": [
    "# Sentences\n",
    "उसने खुशी से कहा\n",
    "\n",
    "1. Noun Verb\n",
    "\n",
    "2. Assumption:  Subject always comes before object\n",
    "    राम ने श्याम को कहा\n",
    "    Subject Object Verb\n",
    "\n",
    "3. Verb Auxiliary Verb\n",
    "\n",
    "4. Verb Adverb\n",
    "\n",
    "5. Noun Adjective\n",
    "\n",
    "-----------------------------------------------------\n",
    "#### Subjective S_Adjective Object O_Adjective Verb Adverb\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cad33a4b-af56-4971-8c93-f90ea08ace67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'उसने', 'xpos': 'PRP', 'id': 1, 'lemma': 'वह', 'deprel': 'nsubj', 'head': 5}, {'text': 'धीरे', 'xpos': 'RB', 'id': 2, 'lemma': 'धीरे', 'deprel': 'advmod', 'head': 3}, {'text': 'चलकर', 'xpos': 'VM', 'id': 3, 'lemma': 'चल', 'deprel': 'advcl', 'head': 5}, {'text': 'स्टेशन', 'xpos': 'NN', 'id': 4, 'lemma': 'स्टेशन', 'deprel': 'obl', 'head': 5}, {'text': 'पहुँचा', 'xpos': 'VM', 'id': 5, 'lemma': 'पहुँच', 'deprel': 'root', 'head': 0}, {'text': '।', 'xpos': 'SYM', 'id': 6, 'lemma': '।', 'deprel': 'punct', 'head': 5}]\n"
     ]
    }
   ],
   "source": [
    "# Extract tags for hindi sentences\n",
    "word_tag = []\n",
    "for sent in doc.sentences:\n",
    "    for word in sent.words:\n",
    "        word_dict = {\n",
    "            \"text\": word.text,\n",
    "            \"xpos\": word.xpos,\n",
    "            \"id\": word.id,\n",
    "            \"lemma\": word.lemma,\n",
    "            \"deprel\": word.deprel,\n",
    "            \"head\": word.head\n",
    "        }\n",
    "        word_tag.append(word_dict)\n",
    "print(word_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "858e6bc7-2626-4339-8e2b-0fe6a2145902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'text': 'उसने', 'xpos': 'PRP', 'id': 1, 'lemma': 'वह', 'deprel': 'nsubj', 'head': 5}, 2: {'text': 'धीरे', 'xpos': 'RB', 'id': 2, 'lemma': 'धीरे', 'deprel': 'advmod', 'head': 3}, 3: {'text': 'चलकर', 'xpos': 'VM', 'id': 3, 'lemma': 'चल', 'deprel': 'advcl', 'head': 5}, 4: {'text': 'स्टेशन', 'xpos': 'NN', 'id': 4, 'lemma': 'स्टेशन', 'deprel': 'obl', 'head': 5}, 5: {'text': 'पहुँचा', 'xpos': 'VM', 'id': 5, 'lemma': 'पहुँच', 'deprel': 'root', 'head': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Removing Unwanted Tags - VAUX CC SYM\n",
    "unwanted_tags = ['VAUX','CC','SYM','PSP']\n",
    "word_tag_cleaned = {}\n",
    "for rel_dict in word_tag:\n",
    "    if rel_dict['xpos'] not in unwanted_tags:\n",
    "        word_tag_cleaned[rel_dict['id']] =  rel_dict\n",
    "print(word_tag_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5ee777d6-4bcf-42a6-a562-40e15e0613ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'text': 'उसने', 'xpos': 'PRP', 'id': 1, 'lemma': 'वह', 'deprel': 'nsubj', 'head': 5}\n",
      "2 {'text': 'धीरे', 'xpos': 'RB', 'id': 2, 'lemma': 'धीरे', 'deprel': 'advmod', 'head': 3}\n",
      "3 {'text': 'चलकर', 'xpos': 'VM', 'id': 3, 'lemma': 'चल', 'deprel': 'advcl', 'head': 5}\n",
      "4 {'text': 'स्टेशन', 'xpos': 'NN', 'id': 4, 'lemma': 'स्टेशन', 'deprel': 'obl', 'head': 5}\n",
      "5 {'text': 'पहुँचा', 'xpos': 'VM', 'id': 5, 'lemma': 'पहुँच', 'deprel': 'root', 'head': 0}\n"
     ]
    }
   ],
   "source": [
    "for key,value in word_tag_cleaned.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659148b0-9d55-4978-9d21-f2f8fd04b7d3",
   "metadata": {},
   "source": [
    "## Converting TO SIGN GRAMMER\n",
    "#### Arrange in Order : Pronoun Subjective S_Adjective Object O_Adjective -> Noun Adjective Verb Adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f240f2c0-ff10-4bbc-a62b-fe1bd430beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dict_order(sample_dict,row_1,row_2):\n",
    "    list_form = [(key,value) for key,value in sample_dict.items()]\n",
    "    index_1 = None     # index_1 \n",
    "    index_2 = None\n",
    "    for i,content in enumerate(list_form):\n",
    "        if content[0] == row_1:\n",
    "            index_1 = i\n",
    "        elif content[0] == row_2:\n",
    "            index_2 = i\n",
    "\n",
    "    entry_1 = list_form.pop(index_1)\n",
    "    print(index_1,index_2,entry_1)\n",
    "    list_form.insert(index_2+1,entry_1)\n",
    "\n",
    "    print(list_form)\n",
    "    \n",
    "\n",
    "    \n",
    "    return_dict = {}\n",
    "    for key,value in list_form:\n",
    "        return_dict[key] = value\n",
    "    return return_dict\n",
    "\n",
    "# sample_dict = {1: \"Yashvir\",\n",
    "#                2: \"Singh\",\n",
    "#                3: \"Nathawat\",\n",
    "#                4: \"ABC\",\n",
    "#               5: \"EFC\"}\n",
    "# output = change_dict_order(sample_dict,2,4)\n",
    "# for key,value in output.items():\n",
    "#     print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "631b7b33-bb92-468d-b1b9-e054fc1a3906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0 (4, {'text': 'स्टेशन', 'xpos': 'NN', 'id': 4, 'lemma': 'स्टेशन', 'deprel': 'obl', 'head': 5})\n",
      "[(1, {'text': 'उसने', 'xpos': 'PRP', 'id': 1, 'lemma': 'वह', 'deprel': 'nsubj', 'head': 5}), (4, {'text': 'स्टेशन', 'xpos': 'NN', 'id': 4, 'lemma': 'स्टेशन', 'deprel': 'obl', 'head': 5}), (2, {'text': 'धीरे', 'xpos': 'RB', 'id': 2, 'lemma': 'धीरे', 'deprel': 'advmod', 'head': 3}), (3, {'text': 'चलकर', 'xpos': 'VM', 'id': 3, 'lemma': 'चल', 'deprel': 'advcl', 'head': 5}), (5, {'text': 'पहुँचा', 'xpos': 'VM', 'id': 5, 'lemma': 'पहुँच', 'deprel': 'root', 'head': 0})]\n"
     ]
    }
   ],
   "source": [
    "# Not Done\n",
    "word_sign_form = word_tag_cleaned.copy()\n",
    "# Format Subject then Object\n",
    "subject_id = None\n",
    "object_id = None\n",
    "subject_index = None \n",
    "object_index = None\n",
    "cnt = 0\n",
    "for key,value in word_tag_cleaned.items():\n",
    "    if value['deprel'] in ['obj','obl']:\n",
    "        object_id = key\n",
    "        object_index = cnt\n",
    "    elif value['deprel']=='nsubj':\n",
    "        subject_id = key\n",
    "        subject_index = cnt\n",
    "    cnt+=1\n",
    "word_sign_form = change_dict_order(word_sign_form,object_id,subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ee030097-493a-47f8-81e7-a09343aa597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'text': 'उसने', 'xpos': 'PRP', 'id': 1, 'lemma': 'वह', 'deprel': 'nsubj', 'head': 5}\n",
      "4 {'text': 'स्टेशन', 'xpos': 'NN', 'id': 4, 'lemma': 'स्टेशन', 'deprel': 'obl', 'head': 5}\n",
      "2 {'text': 'धीरे', 'xpos': 'RB', 'id': 2, 'lemma': 'धीरे', 'deprel': 'advmod', 'head': 3}\n",
      "3 {'text': 'चलकर', 'xpos': 'VM', 'id': 3, 'lemma': 'चल', 'deprel': 'advcl', 'head': 5}\n",
      "5 {'text': 'पहुँचा', 'xpos': 'VM', 'id': 5, 'lemma': 'पहुँच', 'deprel': 'root', 'head': 0}\n"
     ]
    }
   ],
   "source": [
    "for key,value in word_sign_form.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "12b3bc49-fd8e-4d95-a55c-2730263f557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 (2, {'text': 'धीरे', 'xpos': 'RB', 'id': 2, 'lemma': 'धीरे', 'deprel': 'advmod', 'head': 3})\n",
      "[(1, {'text': 'उसने', 'xpos': 'PRP', 'id': 1, 'lemma': 'वह', 'deprel': 'nsubj', 'head': 5}), (4, {'text': 'स्टेशन', 'xpos': 'NN', 'id': 4, 'lemma': 'स्टेशन', 'deprel': 'obl', 'head': 5}), (3, {'text': 'चलकर', 'xpos': 'VM', 'id': 3, 'lemma': 'चल', 'deprel': 'advcl', 'head': 5}), (5, {'text': 'पहुँचा', 'xpos': 'VM', 'id': 5, 'lemma': 'पहुँच', 'deprel': 'root', 'head': 0}), (2, {'text': 'धीरे', 'xpos': 'RB', 'id': 2, 'lemma': 'धीरे', 'deprel': 'advmod', 'head': 3})]\n",
      "{1: {'text': 'उसने', 'xpos': 'PRP', 'id': 1, 'lemma': 'वह', 'deprel': 'nsubj', 'head': 5}, 4: {'text': 'स्टेशन', 'xpos': 'NN', 'id': 4, 'lemma': 'स्टेशन', 'deprel': 'obl', 'head': 5}, 3: {'text': 'चलकर', 'xpos': 'VM', 'id': 3, 'lemma': 'चल', 'deprel': 'advcl', 'head': 5}, 5: {'text': 'पहुँचा', 'xpos': 'VM', 'id': 5, 'lemma': 'पहुँच', 'deprel': 'root', 'head': 0}, 2: {'text': 'धीरे', 'xpos': 'RB', 'id': 2, 'lemma': 'धीरे', 'deprel': 'advmod', 'head': 3}}\n"
     ]
    }
   ],
   "source": [
    "# Arrange Adjective and Adverb\n",
    "for key,value in word_sign_form.items():    # word_tag_cleaned\n",
    "    if value['xpos'] in ['JJ']:     # Adjective Adverb\n",
    "        # first condition is for when it does not have corresponding noun or verb - मैं खुश हूं।\n",
    "        if value['head']!=0 and word_tag_cleaned[value['head']]['xpos'] in ['NN']:\n",
    "            word_sign_form = change_dict_order(word_sign_form,key,value['head'])\n",
    "    elif value['xpos'] in ['RB']:\n",
    "        if value['head']!=0 and word_tag_cleaned[value['head']]['xpos'] in ['VM','VAUX']:\n",
    "            word_sign_form = change_dict_order(word_sign_form,key,value['head'])\n",
    "print(word_sign_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "86d0f059-dd69-49d8-9f1a-01a450617fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange Negative Sentences\n",
    "for key,value in word_sign_form.items():\n",
    "    if value['xpos']=='NEG': \n",
    "        last_key = list(word_sign_form.keys())[-1]\n",
    "        word_sign_form = change_dict_order(word_sign_form,key,last_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec4a17-c6ad-4d7b-8197-c207e004e128",
   "metadata": {},
   "source": [
    "# StopWord Removal - For Sentences like मैं खुश हूं।\n",
    "#### हूं - comes out to be VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6d6aa9b6-a5f5-40be-b999-51efa9cf8da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "['यह', 'जो', 'कि', 'ये', 'हूँ', 'होता है', 'रहे', 'थी', 'थे', 'होना', 'गया', 'किया जा रहा है', 'है', 'पडा', 'होने', 'रही', 'एक', 'लेकिन', 'अगर', 'या', 'जैसा', 'जब तक', 'जबकि', 'की', 'पर', 'द्वारा', 'के लिए', 'के बारे में', 'में', 'के माध्यम से', 'दौरान', 'से पहले', 'के बाद', 'को', 'से', 'तक', 'से नीचे', 'करने में', 'निकल', 'बंद', 'से अधिक', 'तहत', 'दुबारा', 'आगे', 'फिर', 'एक बार', 'यहाँ', 'वहाँ', 'सारे', 'किसी', 'दोनो', 'प्रत्येक', 'ज्यादा', 'अधिकांश', 'अन्य', 'में कुछ', 'ऐसा', 'में कोई', 'मात्र', 'खुद', 'समान', 'इसलिए', 'बहुत', 'सकता', 'जायेंगे', 'जरा', 'चाहिए', 'अभी', 'और', 'कर दिया', 'रखें', 'का', 'हैं', 'इस', 'होता', 'करने', 'ने', 'बनी', 'तो', 'ही', 'हो', 'इसका', 'था', 'हुआ', 'वाले', 'बाद', 'लिए', 'सकते', 'इसमें', 'दो', 'वे', 'वर्ग', 'कई', 'करें', 'होती', 'यदि', 'हुई', 'जा', 'कहते', 'जब', 'होते', 'कोई', 'हुए', 'व', 'जैसे', 'सभी', 'करता', 'उस', 'तरह', 'आदि', 'इसी', 'पे', 'तथा', 'भी', 'परंतु', 'इन', 'कम', 'दूर', 'पूरे', 'गये', 'मै', 'यहां', 'हुये', 'कभी', 'अथवा', 'गयी', 'प्रति', 'इन्हें', 'गई', 'अब', 'जिसमें', 'लिया', 'बड़ा', 'तब', 'उसे', 'लेकर', 'बड़े', 'दूसरे', 'जाने', 'बाहर', 'स्थान', 'उन्हें', 'गए', 'ऐसे', 'जिससे', 'दोनों', 'किए', 'रहती', 'इनके', 'इनका', 'इनकी', 'सकती', 'आज', 'कल', 'जिन्हें', 'जिन्हों', 'तिन्हें', 'तिन्हों', 'इत्यादि', 'बिलकुल', 'निहायत', 'जितना', 'साबुत', 'वग़ैरह', 'लिये', 'जिसे', 'तिसे', 'काफ़ी', 'पहले', 'बाला', 'मानो', 'वहीं', 'जहाँ', 'जीधर', 'के', 'हूं', 'एवं', 'कुछ', 'कुल', 'रहा', 'जिस', 'जिन', 'तिस', 'तिन', 'संग', 'यही', 'मगर', 'कर', 'मे', 'एस', 'उन', 'सो', 'अत']\n"
     ]
    }
   ],
   "source": [
    "# Read stopwords from file\n",
    "with open('final_stopwords.txt', 'r',encoding='utf8') as file:\n",
    "    # Read the entire contents of the file\n",
    "    stopword_list = file.readlines()\n",
    "print('हूं' in stopword_list)\n",
    "stopword_list = [word.strip() for word in stopword_list]\n",
    "print(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a5a534df-a946-479a-be91-951539f7b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_removed_list = {}\n",
    "for key,value in word_tag_cleaned.items():\n",
    "    #print(value['text'] in stopword_list)\n",
    "    if value['text'] not in stopword_list:\n",
    "        stopword_removed_list[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "bd1c67d0-8a61-4bdf-a55f-220fbaa30476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'text': 'उसने', 'xpos': 'PRP', 'id': 1, 'lemma': 'वह', 'deprel': 'nsubj', 'head': 5}\n",
      "2 {'text': 'धीरे', 'xpos': 'RB', 'id': 2, 'lemma': 'धीरे', 'deprel': 'advmod', 'head': 3}\n",
      "3 {'text': 'चलकर', 'xpos': 'VM', 'id': 3, 'lemma': 'चल', 'deprel': 'advcl', 'head': 5}\n",
      "4 {'text': 'स्टेशन', 'xpos': 'NN', 'id': 4, 'lemma': 'स्टेशन', 'deprel': 'obl', 'head': 5}\n",
      "5 {'text': 'पहुँचा', 'xpos': 'VM', 'id': 5, 'lemma': 'पहुँच', 'deprel': 'root', 'head': 0}\n"
     ]
    }
   ],
   "source": [
    "for key,value in stopword_removed_list.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686ca02-4b16-4d06-b580-3bdc2297492a",
   "metadata": {},
   "source": [
    "# Mapping xpos to POS Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0c99404b-f6b5-4efb-9a1c-3ccd3424e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping xpos to POS tags\n",
    "xpos_to_pos = {\n",
    "    'NNP': 'pnoun',\n",
    "    'VM': 'verb',\n",
    "    'VAUX': 'verb',\n",
    "    'JJ': 'adjective',\n",
    "    'RB': 'adverb',\n",
    "    'PRP' : 'pronoun',\n",
    "    'NEG' : 'negative',\n",
    "    'NN' : 'noun',\n",
    "    'RDP' : 'adverb'\n",
    "    # Add more mappings as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "9d4298ba-cb9d-4d2c-95ea-730d5a399596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('उसने', 'pronoun'), ('धीरे', 'adverb'), ('चलकर', 'verb'), ('स्टेशन', 'noun'), ('पहुँचा', 'verb')]\n"
     ]
    }
   ],
   "source": [
    "# Extract Words from Parser and corresponding tag\n",
    "sign_words_list = []\n",
    "for key,value in stopword_removed_list.items():\n",
    "    sign_words_list.append((value['text'],xpos_to_pos[value['xpos']]))\n",
    "print(sign_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b50dac-bc18-44eb-98d4-7aed38eba4f5",
   "metadata": {},
   "source": [
    "## Synonym Substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0236114d-93e8-4a6b-8705-9619b997c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ ISL Dictionary\n",
    "import ast\n",
    "# Open the file in read mode\n",
    "with open('./isl_dict.txt', 'r',encoding='utf8') as file:\n",
    "    # Read the entire contents of the file\n",
    "    isl_dict = ast.literal_eval(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a2a794e3-b0b0-444c-87cd-d3f9cf4ef99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dictionary with lowercase keys\n",
    "isl_dict = {key.lower(): value for key, value in isl_dict.items()}\n",
    "isl_dict['school'] = 'स्कूल'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b6ea41ba-a207-4733-81ca-e1500eaa2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Translator\n",
    "from googletrans import Translator\n",
    "# Create a Translator object\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1956169d-5b79-4e73-a3fa-48e1d9f24ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18:01:21:56,397 INFO     [iwn.py:43] Loading hindi language synsets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_load_synset', '_load_synset_file', '_load_synset_relations', '_relation_list', '_synset_df', '_synset_idx_map', '_synset_relations_dict', '_update_synset_idx_map', 'all_synsets', 'all_words', 'synset_relation', 'synsets']\n",
      "[Synset('आम.noun.3462')]\n",
      "<bound method IndoWordNet.all_synsets of <pyiwn.iwn.IndoWordNet object at 0x000001C49D009C50>>\n"
     ]
    }
   ],
   "source": [
    "# Synonym Substitution\n",
    "import pyiwn\n",
    "from nltk.corpus import wordnet as wn\n",
    "iwn = pyiwn.IndoWordNet() \n",
    "print(dir(iwn))\n",
    "print(iwn.synsets('आम्र'))\n",
    "print(iwn.all_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "62945f12-845e-4762-b1b1-6bfd8a9b698e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1422814046.py, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[238], line 27\u001b[1;36m\u001b[0m\n\u001b[1;33m    if i,synset._head_word in enumerate(list(isl_dict.values())):\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "synonym_substituted_list = []\n",
    "temp_list = [('आकलन', 'noun')]\n",
    "for word,pos_tag in sign_words_list:\n",
    "\n",
    "    # Translate the Hindi sentence to English\n",
    "    english_word = translator.translate(word, src='hi', dest='en').text.lower()\n",
    "    print(english_word)\n",
    "    \n",
    "    if pos_tag == 'pnoun':\n",
    "        synonym_substituted_list.append((word,pos_tag,english_word))\n",
    "        continue\n",
    "    #print(word,pos_tag)\n",
    "    \n",
    "    # Case 1 : Check hindi word in isl_dict\n",
    "    if word in list(isl_dict.values()):\n",
    "        synonym_substituted_list.append((word,pos_tag,english_word))\n",
    "        continue\n",
    "    all_hindi_synsets = []\n",
    "    # Case 2 : Check synonym of hindi_word in isl_dict\n",
    "    try:\n",
    "        all_hindi_synsets = iwn.synsets(word)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        pass\n",
    "    flag = False\n",
    "    for synset in all_hindi_synsets:\n",
    "        if synset._head_word in list(isl_dict.values()):\n",
    "            synonym_substituted_list.append((word,pos_tag,synset._head_word))\n",
    "            flag = True\n",
    "            continue\n",
    "    if flag == True:\n",
    "        continue\n",
    "                \n",
    "    # Case 3 : Check english word in isl_dict\n",
    "    if english_word in list(isl_dict.keys()):\n",
    "        synonym_substituted_list.append((word,pos_tag,english_word))\n",
    "        continue\n",
    "\n",
    "    # Case 4 : Check syno of english word in isl_dict\n",
    "    all_english_synsets = wn.synonyms(english_word)\n",
    "    #print(all_english_synsets)\n",
    "    all_english_synsets_flatten = []\n",
    "    for row in all_english_synsets:\n",
    "        all_english_synsets_flatten.extend(row)\n",
    "    flag = False\n",
    "    for synset in all_english_synsets_flatten:\n",
    "        if synset.lower() in list(isl_dict.keys()):\n",
    "            flag = True\n",
    "            # print('Yes Present')\n",
    "            synonym_substituted_list.append((word,pos_tag,synset.lower()))\n",
    "            break\n",
    "    if flag == True:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    # Case 5 : Most Similar Words using WordNet Path Similarity Concept\n",
    "    #for word in list(isl_dict.keys()):\n",
    "\n",
    "    # Case 6  : Nothing Words Go for Finger Spelling\n",
    "    synonym_substituted_list.append((word,pos_tag,'#'))\n",
    "print(synonym_substituted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2a4a7964-5c69-4e45-b9c0-56b502243502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('उसने', 'pronoun', 'he'), ('धीरे', 'adverb', 'धीरे-धीरे'), ('चलकर', 'verb', '#'), ('स्टेशन', 'noun', 'place'), ('पहुँचा', 'verb', 'arrive')]\n"
     ]
    }
   ],
   "source": [
    "# Final ISL List\n",
    "final_isl_list = synonym_substituted_list.copy()\n",
    "print(final_isl_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a51cf86-f988-4b45-8eeb-1a5c9081f6a8",
   "metadata": {},
   "source": [
    "# Output to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "acf886e5-fd9f-479f-936e-7eaaf4e1675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"manual_output.txt\", 'a', encoding='utf-8') as file:\n",
    "        isl_list = []\n",
    "        for list_1 in synonym_substituted_list:\n",
    "            isl_list.append(list_1)\n",
    "        file.write(str(sentence_list) + \" - \" + str(isl_list) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1570af-2dcc-4bd0-a476-4f2400368ac5",
   "metadata": {},
   "source": [
    "# Video Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f32f543b-b8b2-4e3f-8e83-230f9aea59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversed dictionary mapping Hindi words to English words\n",
    "isl_hindi_english_dict = {hindi_word: english_word for english_word, hindi_word in isl_dict.items()}\n",
    "#print(isl_hindi_english_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "16cca5fc-cb58-4d8a-9971-6aa20cb54e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "def search_videos(folder_path, final_isl_list):\n",
    "    \"\"\"\n",
    "    Searches for video files named after the provided words in a directory.\n",
    "\n",
    "    Args:\n",
    "        folder_path: Path to the directory containing video files.\n",
    "        words: A list of words to search for (video names).\n",
    "\n",
    "    Returns:\n",
    "        A list of paths to the found video files.\n",
    "    \"\"\"\n",
    "\n",
    "    found_videos = []\n",
    "    # Assuming `words` is a list of tuples like [(or_word1, pos_tag1, isl_word1), (or_word2, pos_tag2, isl_word2), ...]\n",
    "    for or_word, pos_tag, isl_word in final_isl_list:\n",
    "        video_name = f\"{isl_word.capitalize()}.mp4\"\n",
    "        if pos_tag == 'pnoun':  # Alphabets\n",
    "            for letter in isl_word:\n",
    "                video_name = f\"{letter.capitalize()}.mp4\"\n",
    "                for root, dirs, files in os.walk(folder_path):\n",
    "                    full_path = os.path.join(root, video_name)\n",
    "                    if os.path.isfile(full_path):\n",
    "                        found_videos.append(full_path)\n",
    "        else:\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                full_path = os.path.join(root, video_name)\n",
    "                if os.path.isfile(full_path):\n",
    "                    found_videos.append(full_path)\n",
    "\n",
    "    return found_videos\n",
    "\n",
    "\n",
    "def play_videos(video_paths):\n",
    "    vlc_path = r'C:\\Program Files\\VideoLAN\\VLC\\vlc.exe'  # Path to VLC media player executable\n",
    "    for video_path in video_paths:\n",
    "        subprocess.Popen([vlc_path, '--fullscreen', video_path])\n",
    "        time.sleep(5)  # Delay before playing the next video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f34f5062-592d-4673-8931-c9b9a8a84383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\desktop\\\\project\\\\Linguistic\\\\H\\\\He.mp4', 'D:\\\\desktop\\\\project\\\\Linguistic\\\\P\\\\Place.mp4', 'D:\\\\desktop\\\\project\\\\Linguistic\\\\A\\\\Arrive.mp4']\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'D:\\desktop\\project\\Linguistic'\n",
    "#print(final_isl_list)\n",
    "video_paths = search_videos(folder_path, final_isl_list)\n",
    "print(video_paths)\n",
    "#play_videos(video_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "072f48c5-87c7-46e7-954c-07a78e698a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video merged_video.mp4.\n",
      "Moviepy - Writing video merged_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready merged_video.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['C:\\\\Program Files\\\\VideoLAN\\\\VLC\\\\vlc.exe',...>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "vlc_path = r'C:\\Program Files\\VideoLAN\\VLC\\vlc.exe' \n",
    "def merge_videos(video_paths):\n",
    "    clips = [VideoFileClip(path) for path in video_paths]\n",
    "    final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "    return final_clip\n",
    "\n",
    "# Merge the videos into a single video\n",
    "merged_clip = merge_videos(video_paths)\n",
    "\n",
    "\n",
    "# Export the merged video to a file\n",
    "merged_clip.write_videofile(\"merged_video.mp4\")\n",
    "\n",
    "# Play the merged video\n",
    "subprocess.Popen([vlc_path, '--fullscreen', 'merged_video.mp4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1586e6d-2cb3-4204-af50-d0cebb2e21be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
